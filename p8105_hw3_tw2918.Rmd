---
title: "p8105_hw3_tw2918"
output: github_document
date: "2023-10-07"
---

```{r, include=FALSE}
library(tidyverse)
library(ggridges)
library(patchwork)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Problem 1

## 1. Load Data

```{r}
library(p8105.datasets)
data("instacart")
```

## 2.  write a short description of the dataset, noting the size and structure of the data, describing some key variables, and giving illustrative examples of observations.

* The dataset contains cleaned and limited data of the “The Instacart Online Grocery Shopping Dataset 2017”, which records theover 3 million online grocery orders from more than 200,000 Instacart users. 
*The dataset contains `r nrow(instacart)` observations and `r ncol(instacart)` variables. Each `row`/observation in the dataset is a product from an order.
* Some variables reflect key identifications of the orders and customers including `order_id` and `order_id`. There is a single order per consumers in this dataset.
* `eval_set`reflects evaluation set this order belongs in, which is exclusively "`train`" in this dataset.
* `order_number` reflects the order sequence number for this user. Its value ranges from `r min(instacart$order_number)` to`r max(instacart$order_number)`. The average order_number is `r mean(instacart$order_number)`. 
* Some variables reflect key information of the products, including `product_id` and `product_name`, which aisle and department the prodcuts are purchased from, including  `aisle_id`,  `aisle`,  `department_id` and  `department`, and the order in which each product was added to cart `add_to_cart_order` , from `r min(instacart$add_to_cart_order)` to `r max(instacart$add_to_cart_order)`. 
* `reordered` variable is a binary indicator off this prodcut has been ordered by this user in the past, 0 otherwise. 
* The rest of the varialbes reflect date and time of the order, including the day of the week on which the order was placed `order_dow` ,  the hour of the day on which the order was placed, `order_hour_of_day`, and days since the last order, capped at `30`, `NA` if `order_number=1`. The average days since the last order is `r mean(instacart$order_hour_of_day)`. 

## 3. Answer questions and comments on result

### Calculate number of aisle in dataset and which aisles is the most items ordered from

```{r}
mode = function(x, na.rm = FALSE) {
  if(na.rm){ #if na.rm is TRUE, remove NA values from input x
    x = x[!is.na(x)]
  }
  val <- unique(x)
  return(val[which.max(tabulate(match(x, val)))])
}

mode(instacart$aisle_id)
mode(instacart$aisle)
```

* There are `r max(instacart$aisle_id)`  aisles in the dataset, and aisle `r mode(instacart$aisle_id)`, `r mode(instacart$aisle)` aisles is the most items ordered from. 


### Make a plot that shows the number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered. Arrange aisles sensibly, and organize your plot so others can read it.

```{r}
instacart |>
  count(aisle)|>
  filter(n > 10000) |>
  mutate(aisle = fct_reorder(aisle, n)) |> 
  ggplot(aes(x = aisle, y = n )) +
  geom_point() +
  labs(
    title = "number of items ordered in each aisle",
    x = "Aisle Name",
    y = "Number of items ordered",
  ) +
  scale_y_continuous(
    limits = c(10000, 160000)
  )+
  theme(axis.text.x =element_text(angle = 60, hjust = 1))
```


### Make a table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”. Include the number of times each item is ordered in your table.

```{r}
instacart |>
  select(aisle, product_name, everything()) |>
  filter(aisle == c("baking ingredients", "dog food care", "packaged vegetables fruits")) |>
  group_by(aisle) |>
  count(product_name)|>
  mutate(rank = min_rank(desc(n)))|>
  filter(rank< 4)|>
  arrange(desc(n))|>
  knitr::kable()
```

### Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week; format this table for human readers (i.e. produce a 2 x 7 table).

```{r}
instacart |>
  select (product_name, order_hour_of_day, order_dow)|>
  filter(product_name == c("Pink Lady Apples", "Coffee Ice Cream")) |>
  mutate(
    dow = recode(order_dow, "0" = "day_0", "1" = "day_1", "2" = "day_2", "3" = "day_3", "4" = "day_4", "5" = "day_5", "6" = "day_6"))|>
  group_by(product_name, dow)|>
  summarize(mean_hour = mean(order_hour_of_day))|>
  pivot_wider(
    names_from = dow,
    values_from = mean_hour
  ) |>
  knitr::kable(digits = 2)
```


# Problem 2 

## 1. Load Data

```{r}
library(p8105.datasets)
data("brfss_smart2010")
```

## 2. Data Cleaning 

```{r}
brfss_df = brfss_smart2010 |>
  janitor::clean_names()|>
  rename(state = locationabbr, state_county = locationdesc) |>
  filter(topic == "Overall Health") |>
  mutate(response = factor(response, levels = c("Poor", "Fair", "Good", "Very good", "Excellent"))) |>
  arrange(response)
```

## 3. Answer Questions

In 2002, which states were observed at 7 or more locations? What about in 2010?

```{r}
brfss_df |>
  filter(year == 2002 | year == 2010) |>
  group_by(year, state)|>
  summarize(location = n_distinct(state_county)) |>
  filter(location>=7) |>
  arrange(year, location) |>
  knitr::kable()
```

* The table shows the states that were observed at 7 or more locations in 2002 and 2010. In 2002,CT,FL,NC,MA NJ, and PA were observed at 7 or more location. In 2010, CO, PA, SC, OH, MA, NY, NE, WA, CA, MD, NC, TX, NJ and FL were observed at 7 or more location. 

Construct a dataset that is limited to Excellent responses, and contains, year, state, and a variable that averages the data_value across locations within a state. Make a “spaghetti” plot of this average value over time within a state (that is, make a plot showing a line for each state across years – the geom_line geometry and group aesthetic will help).

```{r}
brfss_df |>
  filter(response == "Excellent") |>
  group_by(year, state) |>
  summarize(mean_data_value = mean(data_value, na.rm = TRUE)) |>
  ggplot(aes(x = year, y = mean_data_value, color = state )) +
  geom_line() +
   labs(
    title = "Average Data Value Overtime Across States",
    x = "Year",
    y = "Average Data Value",
    color = "State"
    ) 
```

Make a two-panel plot showing, for the years 2006, and 2010, distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY State.

```{r}
brfss_df |>
  filter(year == 2006 | year == 2010, state == "NY") |>
  ggplot(aes(x = response, y = data_value, color = state_county)) +
  geom_point()+
  facet_grid(. ~ year)+
  labs(
    title = "Distribution of Data Value for Responses Among Locations in NY State",
    x = "Response",
    y = "Data Value",
    color = "Location"
    ) 
```

# Problem 3

## 1. Load, tidy, merge, and otherwise organize the data sets.
  Include all originally observed variables
  Exclude participants less than 21 years of age, and those with missing demographic data; 
  And encode data with reasonable variable classes (i.e. not numeric, and using factors with the ordering of tables and plots in mind).

```{r}
nhanes_demo_df = read_csv("./data/nhanes_covar.csv", skip = 4) |>
  janitor::clean_names()|>
  mutate(
    sex = ifelse(sex == 1, "male", "female"),
    education = recode(education,
         "1" = "Less than high school", 
         "2" = "High school equivalent", 
         "3" = "More than high school"
         )
    )|>
  mutate(education = factor(education, levels = c("Less than high school", "High school equivalent", "More than high school")))


nhanes_accel_df = read.csv("./data/nhanes_accel.csv")|>
  janitor::clean_names()

nhanes_df = 
  full_join(nhanes_demo_df, nhanes_accel_df) |>
  drop_na(sex | age | bmi | education)|>
  filter(age >= 21)
```

## 2. Produce a reader-friendly table for the number of men and women in each education category, and create a visualization of the age distributions for men and women in each education category. Comment on these items.

```{r}
nhanes_df |>
  group_by(education)|>
  count(sex)|>
  pivot_wider(
    names_from = "sex",
    values_from = "n"
  )|>
    knitr::kable()

nhanes_df |>
  ggplot(aes(x = education, y = age, fill = sex)) +
  geom_boxplot() +
  stat_summary(fun.y=mean, geom="point", shape=20, size=3, color="red",
             position = position_dodge2(width = 0.75, preserve = "single")) +
    labs(
       title = "Age Distribution for Men and Women in Each Education Category",
        x = "Education category",
        y = "Age",
        color = "Sex"
    )
```

Comment: 

* For the table, I `count` the number of female and male `group_by` `education`, then `pivot_wider` to make the table reader friendly.
* For education, most female and male has `More than high school` education. `Less than high school `  education ranked second for female, and third for male. `High school equivalent` education ranked third for female, and second for male. 
* Male has more `high school equivalent` education level than female; female has more `Less than high school`, and `More than high school` education level than male, but the differences are minor. 
* For the plot, I used `boxplot` to show age distribution in each `edcuation` category, `colored` for male and female.
* The plot shows that, the mean and average age for male and female is similar in `Less than high school` education level, which is around 58 for mean, and 60 for median; female has a higher average and median age than male `high school equivalent` education level, average age is around 58 for female, and 50 for male, median age is around 62 for female and 53 for male; the mean and average age for male and female is similar in `More than high school` education level, which is around 45 for average, and 43 for median. 
* For `Less than high school` and `high school equivalent` education levels, mean is less than median, suggesting left skewed distribution. `More than high school` edcuation level, mean is greater than median, suggesting right skewed distribution. 

## 3 aggregate across minutes to create a total activity variable for each participant. Plot these total activities (y-axis) against age (x-axis); 

your plot should compare men to women and have separate panels for each education level. Include a trend line or a smooth to illustrate differences. Comment on your plot.

```{r}
nhanes_df |>
  mutate(total_activity = rowSums(select(nhanes_df, min1:min1440))) |>
  select(total_activity, everything())|>
  ggplot(aes(x = age, y = total_activity, color = sex)) +
  geom_point() +
  facet_grid(. ~ education) +
  geom_smooth(se = FALSE) +
  labs(
    title = "Distribution of Total Activity against Age for Men and Women in Each Education Category Locations",
    x = "Age",
    y = "Total Activity",
    color = "Sex"
  )
```

Comment:

* Female has a greater total activity than male in `Less than high school`  education category from age 20-40, and lower total activity than male from age 40 to 80. The difference is reducing when at 80 years old, the total activity is almost the same between female and male.  
* Female has a greater total activity than male in `High School euqivalent` in age greater than 25, and lower total activity than male crom 20 to 25. 
* Female has a greater total activity than male in `More than high school` education category across all age groups. 
* Generally speaking, we see a the total activity decreasing when age increases. 

## 4. Accelerometer data allows the inspection activity over the course of the day. Make a three-panel plot that shows the 24-hour activity time courses for each education level and use color to indicate sex. Describe in words any patterns or conclusions you can make based on this graph; including smooth trends may help identify differences.

```{r}
nhanes_df |>
  pivot_longer(
    min1:min1440,
    names_to = "time_min",
    names_prefix = "min",
    values_to = "min_activity"
  )|>
  mutate(time_min = as.numeric(time_min) )|>
  group_by(seqn)|>
  ggplot(aes(x=time_min, y=min_activity, color = sex)) +
  geom_line(alpha = 0.05) +
  geom_smooth(aes(group = sex)) +
  facet_grid(.~ education )
```

Comments:

* The average patterns of activity is similar across all three education levels. The activity decreases from 0 mins to 250 mins (mid-night to early morning) and stays at a low level, and almost reaches 0 at 250 mins. The activity starts to increase at 250 mins from 0 to around 12.5 at 500 mins. It stays constant from 500 mins to 1200 mins (during day time) at around 12.5, and starts to decreases after 1200 mins (during night time).

* The activity data is similar for `Less than high school` and `high school equivalent` education category. For `More than high school` edcuation category, the activity has two peaks at around 500 mins for both male and female and 1500 mins, most ly for female. 


